/* The following code was generated by JFlex 1.4.3 on 15.16.10 13:53 */

package lv.modo.livescriptbrains.lexer;

import com.intellij.lexer.FlexLexer;
import com.intellij.psi.tree.IElementType;

import java.io.IOException;
import java.util.*;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

/**
 * Lexer is the first step of the parsing process â€” it creates semantic "tokens" from a piece of
 * plain text.
 * A token represents a context-less, atomic, smallest piece of the programming language,
 * which will later be combined with others into semantic structures by a parser.
 * For example, the letters "i" and "f" one after another (if they are not part of another word,
 * of course)
 * must be converted into an "if" token.
 */
public class LiveScriptLexer implements FlexLexer
{
	/**
	 * When a new lexer state is entered, the previous one is pushed
	 * on to the stack, and when the state is exited, it's popped
	 * off and resumed again.
	 * This allows for infinite depth of states, which can be
	 * necessary, for example in case of interpolated strings containing
	 * code that contains more interpolated strings and so on.
	 */
	private Stack<Integer> _stateStack;

	/**
	 * Current lexer state.
	 */
	private int _currentState;


	/**
	 * Character index that the lexer is currently at.
	 */
	private int _currentIndex;

	/**
	 * Length of the input text [fragment].
	 */
	private int _textLength;

	/**
	 * Index of the first character in the last token.
	 */
	private int _tokenStartIndex;

	/**
	 * Index of the next character after the token (i.e., last token character index + 1)
	 */
	private int _tokenEndIndex;

	/**
	 * Are tabs used as indents, instead of spaces?
	 */
	private boolean _indentTab;

	/**
	 * How many tabs/spaces wide is one indent.
	 */
	private int _indentSize;

	/**
	 * Text that we're processing.
	 */
	private String _text;

	/**
	 * How many characters the current token consists of.
	 */
	private int _tokenLength = 0;

	private Matcher _matcher = null;

	/**
	 * Found token type.
	 */
	private IElementType _tokenType = null;


	/**
	 * Must always return the position of the first character of whatever the last token returned by
	 * {@link #advance()}.
	 *
	 * @return
	 */
	@Override
	public int getTokenStart()
	{
		return this._tokenStartIndex;
	}

	/**
	 * Must always return the index of the last character in the last token returned by
	 * {@link #advance()}.
	 *
	 * @return
	 */
	@Override
	public int getTokenEnd()
	{
		return this._tokenEndIndex;
	}


	public LiveScriptLexer()
	{
		this._stateStack = new Stack<>();
	}

	/**
	 * Read/process input until a token can be returned, then return it.
	 * <p>This is the main lexer processor method. During the parsing process, this method is called
	 * over and over, to get
	 * the tokens one after another. It must return the next token every time, or <tt>null</tt> when
	 * the end of file
	 * is reached.</p>
	 * <p>
	 * We'll achieve this by taking the whole text buffer as a string, and trying to determine the
	 * first token in it.
	 * When determined, the token is returned, and its content cut from the text buffer, thus when
	 * the method is called
	 * next, it will be working on the text following the last token.
	 * Repeat until there is no more text to parse.
	 * </p>
	 *
	 * @return
	 * @throws IOException
	 */
	@Override
	public IElementType advance() throws IOException
	{
		// Reset/initialize variables
		this._tokenType = null;
		this._tokenLength = 0;

		// If we are at the end of the text, we're done.
		if (this._currentIndex >= this._textLength)
			return this._tokenType;

		LinkedList<Runnable> methods = new LinkedList<>();

		// Here we add all the token matching methods to be run through.
		// Each method tries to detect if there is a token at the start of the text (which gets cut
		// when
		// a token is found, so the start of the text is the index just after the last token).
		// If a token is detected, this._tokenType is set which breaks the loop and stops
		// further checking.
		methods.add(this::_tryExitInterpolation);
		methods.add(this::_tryFullString);

		methods.add(this::_tryComments);
		methods.add(this::_tryPlainStrings);
		methods.add(this::_trySimpleValues);
		methods.add(this::_tryKeywords);

		methods.add(this::_tryId);
		methods.add(this::_tryWhitespace);
		methods.add(this::_tryDot);
		methods.add(this::_tryOperators);

		while (this._tokenType == null && !methods.isEmpty())
		{
			Runnable method = methods.removeFirst();
			method.run();

			if (this.yystate() == LexerState.DOT
				&& this._tokenType != null
				&& this._tokenType != LexerTokens.DOT
				&& this._tokenType != LexerTokens.WHITESPACE)
			{
				this._exitState();
			}
		}


		// If we haven't matched anything, mark the character as unknown/error.
		if (this._tokenType == null)
		{
			this._tokenType = LexerTokens.BAD_CHAR;
			this._tokenLength = 1;
		}
		else
		{
			// If we did match
			if (this._tokenLength == 0)
				this._tokenLength = this._matcher.end();
		}

		// Set the token positions and move the current index just after it.
		this._tokenStartIndex = this._currentIndex;
		this._tokenEndIndex = this._tokenStartIndex + this._tokenLength;
		this._currentIndex = this._tokenEndIndex;
		if (this._currentIndex < this._textLength)
			this._text = this._text.substring(this._tokenLength);

		return this._tokenType;
	}

	private void _tryKeywords()
	{
		if (this._stateIs(LexerState.DOT))
			return;

		LinkedHashMap<String, IElementType> typeMap = new LinkedHashMap<>();

		typeMap.put("^new\\b", LexerTokens.NEW_KEYWORD);
		typeMap.put("^class\\b", LexerTokens.CLASS);
		typeMap.put("^for\\b", LexerTokens.FOR);
		typeMap.put("^from\\b", LexerTokens.FROM);
		typeMap.put("^to\\b", LexerTokens.TO);
		typeMap.put("^til\\b", LexerTokens.TIL);
		typeMap.put("^by\\b", LexerTokens.BY);
		typeMap.put("^in\\b", LexerTokens.IN_KEYWORD);


		for (Map.Entry<String, IElementType> entry : typeMap.entrySet())
		{
			if (this._tryMatch(entry.getKey()))
			{
				this._tokenType = entry.getValue();
				return;
			}
		}
	}

	/**
	 * Matches simple single-quoted strings.
	 */
	private void _tryPlainStrings()
	{
		if (this._stateIsOneOf(LexerStateSet.STRINGS))
			return;

		if (this._tryMatch(LexerPatterns.BACKSTRING)
			|| this._tryMatch("^'{3}.*?'{3}", Pattern.DOTALL)
			|| this._tryMatch("^'(?:\\\\'|.)*?'", Pattern.DOTALL))
		{
			this._tokenType = LexerTokens.STRING_LITERAL;
		}
	}

	/**
	 * Tries to match simple operators.
	 */
	private void _tryOperators()
	{
		LinkedHashMap<String, IElementType> typeMap = new LinkedHashMap<String, IElementType>()
		{{
			put("<<<<", LexerTokens.PROPERTY_COPY);
			put("<<<", LexerTokens.PROPERTY_COPY);
			put("===", LexerTokens.EQ_EQ_EQ);
			put("!==", LexerTokens.NOT_EQ_EQ);
			put("!->", LexerTokens.FUNCTION);
			put("<-!", LexerTokens.FUNCTION);
			put("!~>", LexerTokens.FUNCTION_BIND);
			put("<~!", LexerTokens.FUNCTION_BIND);
			put("!=", LexerTokens.NE);
			put("==", LexerTokens.EQ_EQ);
			put("++", LexerTokens.PLUS_PLUS);
			put("+=", LexerTokens.PLUS_EQ);
			put("--", LexerTokens.MINUS_MINUS);
			put("-=", LexerTokens.MINUS_EQ);
			put("**", LexerTokens.MULT_MULT);
			put("*=", LexerTokens.MULT_EQ);
			put("->", LexerTokens.FUNCTION);
			put("<-", LexerTokens.FUNCTION);
			put("~>", LexerTokens.FUNCTION_BIND);
			put("<~", LexerTokens.FUNCTION_BIND);
			put("=", LexerTokens.EQ);
			put("<", LexerTokens.EQ);
			put(">", LexerTokens.EQ);
			put("+", LexerTokens.PLUS);
			put("-", LexerTokens.MINUS);
			put("*", LexerTokens.MULT);
			put("?", LexerTokens.EXIST);
			put("(", LexerTokens.PARENTHESIS_START);
			put(")", LexerTokens.PARENTHESIS_END);
			put(":", LexerTokens.COLON);
			put(",", LexerTokens.COMMA);
			put("[", LexerTokens.BRACKET_START);
			put("]", LexerTokens.BRACKET_END);
			put("{", LexerTokens.BRACE_START);
			put("}", LexerTokens.BRACE_END);
			put("!", LexerTokens.EXCL);
			put(";", LexerTokens.SEMICOLON);
			put("%", LexerTokens.PERC);
		}};

		for (Map.Entry<String, IElementType> entry : typeMap.entrySet())
		{
			String key = entry.getKey();
			if (this._text.length() >= key.length() && this._text.substring(0, key.length()).equals(key))
			{
				this._tokenType = entry.getValue();
				this._tokenLength = entry.getKey().length();
				return;
			}
		}
	}

	/**
	 * Dot is a special case because if it precedes a keyword, that keyword is interpreted as
	 * an object member instead. So we must mark
	 */
	private void _tryDot()
	{
		if (!this._isNormalState())
			return;

		if (this._tryMatch(LexerPatterns.DOT))
		{
			this._tokenType = LexerTokens.DOT;
			this._enterState(LexerState.DOT);
		}
	}

	private void _tryWhitespace()
	{
		if (!this._isNormalState())
			return;

		if (this._tryMatch(LexerPatterns.WHITESPACE))
			this._tokenType = LexerTokens.WHITESPACE;
	}

	/**
	 * Try a whole range of simple values - numbers, keywords
	 */
	private void _trySimpleValues()
	{
		if (!this._isNormalState())
			return;

		LinkedHashMap<String, IElementType> typeMap = new LinkedHashMap<>();

		// Numbers
		typeMap.put(LexerPatterns.BASED_NUMBER, LexerTokens.NUMBER);
		typeMap.put(LexerPatterns.NUMBER, LexerTokens.NUMBER);
		// Booleans
		typeMap.put(LexerPatterns.BOOLEANS, LexerTokens.BOOLEAN);
		if (this.yystate() != LexerState.DOT)
		{
			// "this"
			typeMap.put(LexerPatterns.THIS, LexerTokens.THIS);
			typeMap.put(LexerPatterns.NULL, LexerTokens.EMPTY);
			typeMap.put(LexerPatterns.IF, LexerTokens.IF);
			typeMap.put(LexerPatterns.THEN, LexerTokens.THEN);
			typeMap.put(LexerPatterns.ELSE, LexerTokens.ELSE);
			typeMap.put(LexerPatterns.UNLESS, LexerTokens.UNLESS);

			// RegEx
			typeMap.put(LexerPatterns.REGEX, LexerTokens.REGEX_LITERAL);
		}


		for (Map.Entry<String, IElementType> token : typeMap.entrySet())
		{
			if (this._tryMatch(token.getKey()))
			{
				this._tokenType = token.getValue();
				return;
			}
		}
	}

	/**
	 * When inside the interpolation part of a string, check for when it's closed.
	 */
	private void _tryExitInterpolation()
	{
		if (this._stateIsOneOf(LexerState.INTERPOLATED) && this._tryMatch("^}"))
		{
			this._tokenType = LexerTokens.INTERPOLATION_END;
			this._exitState();
		}
	}

	/**
	 * Match comment tokens.
	 */
	private void _tryComments()
	{
		if (!this._isNormalState())
			return;

		if (this._tryMatch("^/\\*.*?\\*/", Pattern.DOTALL))
			this._tokenType = LexerTokens.COMMENT_BLOCK;
		else if (this._tryMatch("^#.*"))
			this._tokenType = LexerTokens.COMMENT_LINE;
	}

	private void _tryFullString()
	{
		String suffix;
		if (this._stateIs(LexerState.HEREDOC))
			suffix = "\"{3}";
		else if (this._stateIs(LexerState.REGEX))
			suffix = "//[gmi]{0,3}";
		else
			suffix = "\"";

		// First we check if we are inside a string/regex, in which case everything up to
		// interpolation / end of string is a string.
		if (this._stateIsOneOf(LexerStateSet.STRINGS))
		{
			// Check if we're at an interpolation point
			if (this._tryMatch("^(#\\{|#[^ ])"))
			{
				if (this._matcher.group(1).equals("#{"))
				{
					this._enterState(LexerState.INTERPOLATED);
					this._tokenType = LexerTokens.INTERPOLATION_START;
				}
				else
				{
					this._enterState(LexerState.INTERPOLATED_VAR);
					this._tokenType = LexerTokens.INTERPOLATED_VAR_START;
					// We need to move back 1 char to only include the "#" in the token.
					this._tokenLength = this._matcher.end() - 1;
				}
				return;
			}

			// Check if we're at a regex comment point
			if (this._tryMatch(LexerPatterns.REGEX_COMMENT)) {
				this._tokenType = LexerTokens.COMMENT_LINE;
				return;
			}

			this._tokenType = this._stateIs(LexerState.REGEX)
				? LexerTokens.REGEX
				: LexerTokens.STRING;


			// Match until end or interpolation (or regex comment).
			if (this._tryMatch("^(?:\\\\\"|\\\\/|\\\\#|/[^/]|[^\"/])*?(#\\{|# |#)", Pattern.DOTALL))
			{
				this._tokenLength = this._matcher.end() - this._matcher.group(1).length();
				return;
			}
			if (this._tryMatch("^(?:\\\\\"|\\\\/|\\\\#|[^#])*?(" + suffix + ")", Pattern.DOTALL))
			{
				this._tokenLength = this._matcher.end() - this._matcher.group(1).length();
			}
		}

		// Only if we're *not* inside a string already (or are at an end of one), do we check for
		// starting / ending.
		if (this._stateIsOneOf(LexerStateSet.STRINGS))
		{
			if (this._tryMatch("^" + suffix))
			{
				this._tokenType = suffix.startsWith("//")
					? LexerTokens.REGEX_END
					: LexerTokens.STRING_END;
				this._exitState();
			}
		}
		else if (this._tryMatch("^(\"{3}|\"|//)"))
		{
			if (this._matcher.group(1).equals("//"))
			{
				this._enterState(LexerState.REGEX);
				this._tokenType = LexerTokens.REGEX_START;
			}
			else
			{
				this._tokenType = LexerTokens.STRING_START;
				this._enterState(
					this._matcher.group(1).equals("\"")
						? LexerState.STRING
						: LexerState.HEREDOC);
			}
		}
	}

	private void _tryId()
	{
		if (!this._isNormalState() && !this._stateIsOneOf(LexerState.INTERPOLATED, LexerState
			.INTERPOLATED_VAR))
			return;

		if (this._tryMatch("^" + LexerPatterns.ID))
		{
			this._tokenType = LexerTokens.IDENTIFIER;
			if (this.yystate() == LexerState.INTERPOLATED_VAR)
				this._exitState();
		}
	}

	private boolean _isNormalState()
	{
		return this._stateIsOneOf(LexerState.NORMAL, LexerState.INTERPOLATED, LexerState.DOT);
	}

	/**
	 * @param states
	 * @return
	 */
	private boolean _stateIsOneOf(int... states)
	{
		for (int state : states)
		{
			if (this.yystate() == state)
				return true;
		}
		return false;
	}

	private boolean _stateIsOneOf(Iterable<Integer> states)
	{
		for (Integer state : states)
		{
			if (this._stateIs(state))
				return true;
		}
		return false;
	}

	private boolean _stateIs(int state)
	{
		return this.yystate() == state;
	}

	private Character _getIndentChar()
	{
		return this._indentTab ? '\t' : ' ';
	}


	private boolean _tryMatch(String patternString, int flags)
	{
		return _tryMatch(patternString, flags, 0);
	}

	private boolean _tryMatch(String patternString, int flags, int startAt)
	{
		Pattern pattern = Pattern.compile(patternString, flags);
		this._matcher = pattern.matcher(this._text);
		return this._matcher.find(startAt);
	}

	private boolean _tryMatch(String patternString)
	{
		return this._tryMatch(patternString, 0, 0);
	}

	/**
	 * Commands the lexer to start over from the beginning.
	 * The lexing process starts with this entry point, receiving the text and its
	 *
	 * @param buf          Text to parse for tokens.
	 * @param start        The starting position of the text. Usually 0, but can be larger if only a
	 *                     fragment of text is processed.
	 * @param end          Ending position of the text. Usually text.length, but can be smaller if
	 *                     only a fragment is used.
	 * @param initialState ?
	 */
	@Override
	public void reset(CharSequence buf, int start, int end, int initialState)
	{
		this._currentIndex = start;
		this._textLength = end;
		this._text = buf.toString().substring(start, end);
		this._stateStack = new Stack<>();
		this._currentState = initialState;
	}


	/**
	 * Go back to the previous lexer state (or {@link LexerState#NORMAL} if
	 * there is no previous state.
	 */
	private void _exitState()
	{
		if (this._stateStack.empty())
		{
			this._currentState = LexerState.NORMAL;
			return;
		}
		this._currentState = this._stateStack.pop();
	}

	private void _enterState(int state)
	{
		this.yybegin(state);
	}


	/**
	 * Enter a new lexer state.
	 *
	 * @param state
	 */
	@Override
	public void yybegin(int state)
	{
		this._stateStack.push(this._currentState);
		this._currentState = state;
	}

	/**
	 * Return current lexer state.
	 *
	 * @return
	 */
	@Override
	public int yystate()
	{
		return this._currentState;
	}

}
